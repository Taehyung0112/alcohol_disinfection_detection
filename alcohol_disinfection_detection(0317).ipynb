{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/usr/lib/aarch64-linux-gnu/libgobject-2.0.so.0: undefined symbol: ffi_type_uint32, version LIBFFI_BASE_7.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /usr/lib/aarch64-linux-gnu/libgobject-2.0.so.0: undefined symbol: ffi_type_uint32, version LIBFFI_BASE_7.0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# è¨­å®šè·¯å¾‘\n",
    "YOLO_DISPENSER_MODEL = os.path.join(\"/home/yangzhelun/Desktop/alcohol_disinfection_detection-main\", \"dispensor weight/best.pt\")  # é…’ç²¾æ©Ÿæ¨¡å‹\n",
    "VIDEO_INPUT = os.path.join(\"/home/yangzhelun/Desktop/alcohol_disinfection_detection-main\", \"Input Video/IMG_7129.mp4\")          # è¼¸å…¥å½±ç‰‡\n",
    "VIDEO_OUTPUT = os.path.join(\"/home/yangzhelun/Desktop/alcohol_disinfection_detection-main\", \"Output Video/processed_video.mp4\")  # è¼¸å‡ºå½±ç‰‡\n",
    "\n",
    "# Mediapipe åˆå§‹åŒ–\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.3, min_tracking_confidence=0.3)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# åˆå§‹åŒ– YOLO æ¨¡å‹\n",
    "model_people = YOLO(\"yolov8n.pt\")\n",
    "model_dispenser = YOLO(YOLO_DISPENSER_MODEL)\n",
    "\n",
    "# å…¨åŸŸè®Šæ•¸\n",
    "dispenser_roi = None\n",
    "sanitized_count = 0\n",
    "sanitized_ids = set()\n",
    "track_state = {}\n",
    "INTERSECTION_THRESHOLD = 0.1\n",
    "DELAY_TIME = 3\n",
    "\n",
    "\n",
    "# å½±ç‰‡åˆå§‹åŒ–func\n",
    "def initialize_video(input_path, output_path):\n",
    "    \"\"\" åˆå§‹åŒ–å½±ç‰‡è®€å–å’Œå¯«å…¥ \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    return cap, out, fps, frame_width, frame_height\n",
    "\n",
    "# é…’ç²¾åµæ¸¬(yolov8)func\n",
    "def detect_dispenser(frame):\n",
    "    \"\"\" åµæ¸¬é…’ç²¾æ©Ÿä¸¦è¿”å›ä½ç½® \"\"\"\n",
    "    results = model_dispenser(frame)\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls_id = int(box.cls.item())  # ç²å–é¡åˆ¥ ID\n",
    "            label = r.names[cls_id]  # ç²å–class name\n",
    "            confidence = box.conf[0]  # ç²å–confidence\n",
    "            print(f\"Detected: {label}, Confidence: {confidence:.2f}\")\n",
    "            \n",
    "            if label.lower() == \"dispenser\" and confidence > 0.3:  # ç¢ºä¿åç¨±åŒ¹é…\n",
    "                print(f\"Dispenser detected at: {box.xyxy[0].tolist()}\")  # é¡¯ç¤ºåº§æ¨™\n",
    "                return list(map(int, box.xyxy[0]))  # è¿”å›æ•´æ•¸åº§æ¨™\n",
    "            \n",
    "    print(\"No dispenser detected.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# è¨ˆç®—äººç‰©èˆ‡é…’ç²¾æ©Ÿå™¨é‡ç–Šæ¯”ä¾‹åˆ¤æ–·æ˜¯å¦\"çœŸæ­£é è¿‘\"\n",
    "def calculate_intersection_ratio(person_box, dispenser_roi):\n",
    "    \"\"\" è¨ˆç®—äººèˆ‡é…’ç²¾æ©Ÿçš„é‡ç–Šæ¯”ä¾‹ \"\"\"\n",
    "    def calculate_area(box):\n",
    "        return max(0, box[2] - box[0]) * max(0, box[3] - box[1])\n",
    "\n",
    "    x1 = max(person_box[0], dispenser_roi[0])\n",
    "    y1 = max(person_box[1], dispenser_roi[1])\n",
    "    x2 = min(person_box[2], dispenser_roi[2])\n",
    "    y2 = min(person_box[3], dispenser_roi[3])\n",
    "    intersection_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    return intersection_area / min(calculate_area(person_box), calculate_area(dispenser_roi))\n",
    "\n",
    "\n",
    "def process_hand_detection(frame, dispenser_roi, track_id, w, h):\n",
    "    \"\"\" ä½¿ç”¨ Mediapipe æª¢æ¸¬æ‰‹éƒ¨ä¸¦ç¢ºèªæ˜¯å¦é€²è¡Œæ¶ˆæ¯’ \"\"\"\n",
    "    global sanitized_count\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    hand_results = hands.process(rgb_frame)\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            lower_edge_start = dispenser_roi[1] + int((dispenser_roi[3] - dispenser_roi[1]) * 0.8)\n",
    "            lower_edge_end = dispenser_roi[3]\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                hand_x = int(lm.x * w)\n",
    "                hand_y = int(lm.y * h)\n",
    "                if dispenser_roi[0] <= hand_x <= dispenser_roi[2] and lower_edge_start <= hand_y <= lower_edge_end:\n",
    "                    if track_id not in sanitized_ids:\n",
    "                        sanitized_ids.add(track_id)\n",
    "                        sanitized_count += 1\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def process_tracking(frame, results_people, dispenser_roi, w, h, current_time):\n",
    "    \"\"\" è™•ç†äººç‰©è¿½è¹¤é‚è¼¯ \"\"\"\n",
    "    for r in results_people:\n",
    "        for box, track_id_tensor in zip(r.boxes, r.boxes.id):\n",
    "            track_id = int(track_id_tensor.item())\n",
    "            cls_id = int(box.cls.item())  # ä¿®æ­£æ­¤è¡Œ\n",
    "            label = r.names[cls_id]\n",
    "            \n",
    "            # åªè¿½è¹¤äººé¡\n",
    "            if label != \"person\":\n",
    "                continue\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            person_box = (x1, y1, x2, y2)\n",
    "\n",
    "            # åˆå§‹åŒ–è¿½è¹¤ç‹€æ…‹\n",
    "            track_state.setdefault(track_id, {'last_detected': 0, 'show_text': False})\n",
    "\n",
    "            # è¨ˆç®—é‡ç–Šç‡\n",
    "            overlap_ratio = calculate_intersection_ratio(person_box, dispenser_roi)\n",
    "\n",
    "            # æ‰‹éƒ¨æª¢æ¸¬é‚è¼¯\n",
    "            if overlap_ratio > INTERSECTION_THRESHOLD:\n",
    "                if (current_time - track_state[track_id]['last_detected']) > DELAY_TIME:\n",
    "                    if process_hand_detection(frame, dispenser_roi, track_id, w, h):\n",
    "                        track_state[track_id] = {'last_detected': current_time, 'show_text': True}\n",
    "\n",
    "            # é¡¯ç¤ºæç¤ºæ–‡å­—\n",
    "            if track_state[track_id]['show_text']:\n",
    "                cv2.putText(frame, \"Sanitization Success!\", (w // 4, h // 2),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "\n",
    "            # ç¹ªè£½æ¡†èˆ‡ ID\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "# ä¸»ç¨‹å¼\n",
    "cap, out, fps, frame_width, frame_height = initialize_video(VIDEO_INPUT, VIDEO_OUTPUT)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"è™•ç†å®Œæˆ\")\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    if dispenser_roi is None:\n",
    "        dispenser_roi = detect_dispenser(frame)\n",
    "        continue\n",
    "\n",
    "    results_people = model_people.track(frame, persist=True, tracker=\"botsort.yaml\")\n",
    "    process_tracking(frame, results_people, dispenser_roi, w, h, current_time)\n",
    "\n",
    "    # ç¹ªè£½æ¶ˆæ¯’è¨ˆæ•¸\n",
    "    cv2.putText(frame, f\"Sanitized Count: {sanitized_count}\", (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Jetson Nano Sanitization Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'imshow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mediapipe_env2/lib/python3.8/site-packages/ultralytics/__init__.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# default for reduced CPU utilization during training\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, YOLOE, FastSAM, YOLOWorld\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_yolo \u001b[38;5;28;01mas\u001b[39;00m checks\n",
      "File \u001b[0;32m~/miniconda3/envs/mediapipe_env2/lib/python3.8/site-packages/ultralytics/models/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastsam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NAS\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrtdetr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "File \u001b[0;32m~/miniconda3/envs/mediapipe_env2/lib/python3.8/site-packages/ultralytics/models/fastsam/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[0;32m~/miniconda3/envs/mediapipe_env2/lib/python3.8/site-packages/ultralytics/models/fastsam/model.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[0;32m~/miniconda3/envs/mediapipe_env2/lib/python3.8/site-packages/ultralytics/engine/model.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcfg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TASK2DATA, get_cfg, get_save_dir\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresults\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Results\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HUB_WEB_ROOT, HUBTrainingSession\n",
      "File \u001b[0;32m~/miniconda3/envs/mediapipe_env2/lib/python3.8/site-packages/ultralytics/cfg/__init__.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Union\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     ASSETS,\n\u001b[1;32m     14\u001b[0m     DEFAULT_CFG,\n\u001b[1;32m     15\u001b[0m     DEFAULT_CFG_DICT,\n\u001b[1;32m     16\u001b[0m     DEFAULT_CFG_PATH,\n\u001b[1;32m     17\u001b[0m     DEFAULT_SOL_DICT,\n\u001b[1;32m     18\u001b[0m     IS_VSCODE,\n\u001b[1;32m     19\u001b[0m     LOGGER,\n\u001b[1;32m     20\u001b[0m     RANK,\n\u001b[1;32m     21\u001b[0m     ROOT,\n\u001b[1;32m     22\u001b[0m     RUNS_DIR,\n\u001b[1;32m     23\u001b[0m     SETTINGS,\n\u001b[1;32m     24\u001b[0m     SETTINGS_FILE,\n\u001b[1;32m     25\u001b[0m     TESTS_RUNNING,\n\u001b[1;32m     26\u001b[0m     IterableSimpleNamespace,\n\u001b[1;32m     27\u001b[0m     __version__,\n\u001b[1;32m     28\u001b[0m     checks,\n\u001b[1;32m     29\u001b[0m     colorstr,\n\u001b[1;32m     30\u001b[0m     deprecation_warn,\n\u001b[1;32m     31\u001b[0m     vscode_msg,\n\u001b[1;32m     32\u001b[0m     yaml_load,\n\u001b[1;32m     33\u001b[0m     yaml_print,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Define valid solutions\u001b[39;00m\n\u001b[1;32m     37\u001b[0m SOLUTION_MAP \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectCounter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrop\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectCropper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/mediapipe_env2/lib/python3.8/site-packages/ultralytics/utils/__init__.py:31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m imread, imshow, imwrite, torch_load, torch_save  \u001b[38;5;66;03m# for patches\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# PyTorch Multi-GPU DDP Constants\u001b[39;00m\n\u001b[1;32m     34\u001b[0m RANK \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRANK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/mediapipe_env2/lib/python3.8/site-packages/ultralytics/utils/patches.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# OpenCV Multilanguage-friendly functions ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m _imshow \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m  \u001b[38;5;66;03m# copy to avoid recursion errors\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Read an image from a file.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'imshow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# === è¨­å®šè·¯å¾‘ ===\n",
    "YOLO_DISPENSER_MODEL = \"/home/jetson/projects/weights/best.engine\"\n",
    "YOLO_PEOPLE_MODEL = \"/home/jetson/projects/weights/yolov8n.engine\"\n",
    "VIDEO_INPUT = \"/home/jetson/projects/videos/input.mp4\"\n",
    "VIDEO_OUTPUT = \"/home/jetson/projects/videos/output.mp4\"\n",
    "\n",
    "# === Mediapipe åˆå§‹åŒ– ===\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.3, min_tracking_confidence=0.3)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# === è¼‰å…¥ TensorRT æ¨¡å‹ ===\n",
    "model_people = YOLO(YOLO_PEOPLE_MODEL)\n",
    "model_dispenser = YOLO(YOLO_DISPENSER_MODEL)\n",
    "\n",
    "# === å…¨åŸŸè®Šæ•¸ ===\n",
    "dispenser_roi = None\n",
    "sanitized_count = 0\n",
    "sanitized_ids = set()\n",
    "track_state = {}\n",
    "INTERSECTION_THRESHOLD = 0.1\n",
    "DELAY_TIME = 3\n",
    "\n",
    "\n",
    "def initialize_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    return cap, out, fps, frame_width, frame_height\n",
    "\n",
    "\n",
    "def detect_dispenser(frame):\n",
    "    results = model_dispenser(frame)\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls_id = int(box.cls.item())\n",
    "            label = r.names[cls_id]\n",
    "            confidence = box.conf[0]\n",
    "            if label.lower() == \"dispenser\" and confidence > 0.3:\n",
    "                print(f\"Detected dispenser at: {box.xyxy[0].tolist()}\")\n",
    "                return list(map(int, box.xyxy[0]))\n",
    "    print(\"No dispenser detected.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def calculate_intersection_ratio(person_box, dispenser_roi):\n",
    "    def area(box):\n",
    "        return max(0, box[2] - box[0]) * max(0, box[3] - box[1])\n",
    "\n",
    "    x1 = max(person_box[0], dispenser_roi[0])\n",
    "    y1 = max(person_box[1], dispenser_roi[1])\n",
    "    x2 = min(person_box[2], dispenser_roi[2])\n",
    "    y2 = min(person_box[3], dispenser_roi[3])\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    return inter_area / min(area(person_box), area(dispenser_roi))\n",
    "\n",
    "\n",
    "def process_hand_detection(frame, dispenser_roi, track_id, w, h):\n",
    "    global sanitized_count\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)\n",
    "            lower_start = dispenser_roi[1] + int((dispenser_roi[3] - dispenser_roi[1]) * 0.8)\n",
    "            lower_end = dispenser_roi[3]\n",
    "            for lm in hand.landmark:\n",
    "                x = int(lm.x * w)\n",
    "                y = int(lm.y * h)\n",
    "                if dispenser_roi[0] <= x <= dispenser_roi[2] and lower_start <= y <= lower_end:\n",
    "                    if track_id not in sanitized_ids:\n",
    "                        sanitized_ids.add(track_id)\n",
    "                        sanitized_count += 1\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def process_tracking(frame, results_people, dispenser_roi, w, h, current_time):\n",
    "    for r in results_people:\n",
    "        for box, track_id_tensor in zip(r.boxes, r.boxes.id):\n",
    "            track_id = int(track_id_tensor.item())\n",
    "            cls_id = int(box.cls.item())\n",
    "            label = r.names[cls_id]\n",
    "            if label != \"person\":\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            person_box = (x1, y1, x2, y2)\n",
    "            track_state.setdefault(track_id, {'last_detected': 0, 'show_text': False})\n",
    "\n",
    "            overlap_ratio = calculate_intersection_ratio(person_box, dispenser_roi)\n",
    "            if overlap_ratio > INTERSECTION_THRESHOLD:\n",
    "                if (current_time - track_state[track_id]['last_detected']) > DELAY_TIME:\n",
    "                    if process_hand_detection(frame, dispenser_roi, track_id, w, h):\n",
    "                        track_state[track_id] = {'last_detected': current_time, 'show_text': True}\n",
    "\n",
    "            if track_state[track_id]['show_text']:\n",
    "                cv2.putText(frame, \"Sanitization Success!\", (w // 4, h // 2),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "# === ä¸»ç¨‹å¼é–‹å§‹ ===\n",
    "cap, out, fps, frame_width, frame_height = initialize_video(VIDEO_INPUT, VIDEO_OUTPUT)\n",
    "\n",
    "frame_count = 0\n",
    "display_every_n_frames = 3  # æ¯ N å¹€é¡¯ç¤ºä¸€æ¬¡ç•«é¢ï¼Œé¿å…é¡¯ç¤ºå¤ªæ…¢\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"è™•ç†å®Œæˆ\")\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    if dispenser_roi is None:\n",
    "        dispenser_roi = detect_dispenser(frame)\n",
    "        continue\n",
    "\n",
    "    results_people = model_people.track(frame, persist=True, tracker=\"botsort.yaml\")\n",
    "    process_tracking(frame, results_people, dispenser_roi, w, h, current_time)\n",
    "\n",
    "    cv2.putText(frame, f\"Sanitized Count: {sanitized_count}\", (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    # âœ… Matplotlib é¡¯ç¤ºç•«é¢\n",
    "    if frame_count % display_every_n_frames == 0:\n",
    "        clear_output(wait=True)\n",
    "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Jetson Xavier Sanitization Detection\")\n",
    "        plt.show()\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mediapipe_env2)",
   "language": "python",
   "name": "mediapipe_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
